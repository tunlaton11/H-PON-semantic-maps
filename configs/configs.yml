nuscenes_dir: nuscenes
nuscenes_version: v1.0-mini
label_dir: labels
log_dir: runs
checkpoint_dir: checkpoints

# Number of epochs
epochs: 100

# Number of examples per mini-batch
batch_size: 8

# Number of dataloader threads
num_workers: 2

# Learning rate
lr: 0.001

# multiclass or multilabel
method_type: multilabel

train_scenes:
  [
    'scene-0103',
    # 'scene-0103',
    # 'scene-0553',
    # 'scene-0796',
    # 'scene-0916',
    # 'scene-1077',
    # 'scene-1094',
  ]
val_scenes:
  [ 
    'scene-0103',
    # 'scene-0655',
    # 'scene-0757',
    # 'scene-1100',
  ]

train_tokens: # 1 scene
  ['f1680ea9126e468ca407f7284efc980c',
  'bf4b00d2af9344c3b3f444206f75cf14',
  '73fffafd944c4c42a32cfcaeeafc4944',
  '9d8d518a34ff462d8d6a8fb665d5edd4',
  'd209059d97174d28a279f467e9cf89f0',
  '19f4244aa37b42a49a005b8ea6d53953',
  'c33b84588ead4a609f195d2c4fb56801',
  '731b03604b4849f0aa646d0b46571451',
  'f331f492972540ab8e843d484ac6919e',
  '834ce773cfa04be8b56d9614ed1dcf7f',
  '50e02dd80f9444a194abe8acae4bb211',
  'd507acb08ec94f00b54bd650bb4b1c52',
  'b4f9181a80034d22972433e4d1dd9f9e',
  'b04ad7e3c86d47fc98dba25595b2327e',
  '76542abab799469cbfb7b293c83192aa',
  'beea8d83b337481799c36c6561ec3de6',
  '6830e208ec3b444f878c8f5c11135dc6',
  'deb67484315f4ba8b56ea8f03ef3d444',
  'f059772e809443b787af4bb7c60c094a',
  '9b6ce88572b947b3b8e141c8bfe96f5b',
  '3cd43f6baa4e444999eef6cb1c89416a',
  'e26810c28df44cefa069778865bd832c',
  '881817a81bab4d8488464ac42db89f5f',
  'e30d5ecf0fd6418089112b4e4811737c',
  'eeed80879b3d4580804a0da6bf9c84e2',
  'b732ab7ce371484b93ba0c2d2b2f9ae7',
  'fc4cba53bd2c4923b17da19b2e6e44fa',
  '7b6c123b090340358e642a70c6fda96d'
  ]

val_tokens: # 1 scene
  ['df1863e3fe614f288a9974d619343050',
  'f921ab741862402aa867b4cd7ceb3d40',
  '9ce08dbf60bb4b22a952e11f56504292',
  '35480f511677406fa35386f153291792',
  '029dc949763249ddbeb3f756cb7b259f',
  'f225d67c5e1e4f2e8f86fd9b7d2cb9e1',
  '5cfd339fb1cc4c84881d9bf2a48e1f46',
  '452cb8aa72de4124907764018407b8d8',
  '85640ff86e61419993ae9a3f9ac456eb',
  '5e862f5aad0444f199824efc78edfff0',
  '17b8884e21844ad9bf5df19a141a1156',
  'b7b3ad2c218c4192ab958334ea15303f',
  '0a7aef80edbc4854bcd781a3becb943c'
  ]




# Top-left and bottom right coordinates of map region, in meters
map_extents: [-25.0, 1.0, 25.0, 50.0]
# Spacing between adjacent grid cells in the map, in meters
map_resolution: 0.25


# Vertical extents of the region of interest, in meters
ymin: -2
ymax: 4

# Approximate camera focal length used for constructing transformers
focal_length: 630.

# Number of intermediate channels in the transformer layer
tfm_channels: 64

# Number of output classes to predict
num_class: 14

# Topdown network options
topdown:

  # Number of feature channels at each layer of the topdown network
  channels: 128

  # Number of blocks in each layer
  layers: [4, 4]

  # Upsampling factor in each stage of the topdown network
  strides: [1, 2]

  # Type of residual block to use [ basic | bottleneck ]
  blocktype: bottleneck

# Whether to use Bayesian classifier
bayesian: False

# Class-specific weighting factors used to balance the cross entropy loss
class_weights:
  -    1.7    # drivable_area
  -    5.9    # ped_crossing
  -    3.3    # walkway
  -    4.6    # carpark
  -    8.0    # car
  -   10.3    # truck
  -   10.6    # bus
  -    6.9    # trailer
  -   11.8    # construction_vehicle
  -   30.1    # pedestrian
  -   33.6    # motorcycle
  -   41.2    # bicycle
  -   44.3    # traffic_cone
  -   15.9    # barrier

# Prior probability of a positive prediction, used to initialise classifier
prior:
  - 0.44679   # drivable_area
  - 0.02407   # ped_crossing
  - 0.14491   # walkway
  - 0.02994   # carpark
  - 0.02086   # car
  - 0.00477   # truck
  - 0.00156   # bus
  - 0.00189   # trailer
  - 0.00084   # construction_vehicle
  - 0.00119   # pedestrian
  - 0.00019   # motorcycle
  - 0.00012   # bicycle
  - 0.00031   # traffic_cone
  - 0.00176   # barrier